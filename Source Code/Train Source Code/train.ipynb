{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "class FaceRecognitionModel:\n",
    "    def __init__(self, \n",
    "                 dataset_path, \n",
    "                 img_height=299, \n",
    "                 img_width=299, \n",
    "                 batch_size=32, \n",
    "                 num_classes=None,\n",
    "                 dropout_rate=0.5,\n",
    "                 l2_regularization=1e-4):\n",
    "        \"\"\"\n",
    "        Initialize Face Recognition Model with Inception V3\n",
    "        \n",
    "        Parameters:\n",
    "        - dataset_path: Path to the directory containing face images\n",
    "        - img_height: Image height for resizing (default Inception V3 input)\n",
    "        - img_width: Image width for resizing\n",
    "        - batch_size: Training batch size\n",
    "        - num_classes: Number of face classes/identities\n",
    "        \"\"\"\n",
    "        self.dataset_path = dataset_path\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "        self.batch_size = batch_size\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.l2_regularization = l2_regularization\n",
    "        \n",
    "        # Detect number of classes automatically\n",
    "        if num_classes is None:\n",
    "            self.num_classes = len(os.listdir(dataset_path))\n",
    "        else:\n",
    "            self.num_classes = num_classes\n",
    "        \n",
    "        # Model and training attributes\n",
    "        self.model = None\n",
    "        self.history = None\n",
    "        self.best_model = None\n",
    "        \n",
    "    def _create_data_generators(self):\n",
    "        \"\"\"\n",
    "        Create data generators with aggressive augmentation\n",
    "        \"\"\"\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            preprocessing_function=preprocess_input,\n",
    "            rotation_range=20,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            brightness_range=(0.8, 1.2),\n",
    "            fill_mode='nearest',\n",
    "            validation_split=0.2\n",
    "        )\n",
    "        \n",
    "        train_generator = train_datagen.flow_from_directory(\n",
    "            self.dataset_path,\n",
    "            target_size=(self.img_height, self.img_width),\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='categorical',\n",
    "            subset='training'\n",
    "        )\n",
    "        \n",
    "        validation_generator = train_datagen.flow_from_directory(\n",
    "            self.dataset_path,\n",
    "            target_size=(self.img_height, self.img_width),\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='categorical',\n",
    "            subset='validation'\n",
    "        )\n",
    "        \n",
    "        return train_generator, validation_generator\n",
    "    \n",
    "    def build_model(self, learning_rate=1e-4):\n",
    "        \"\"\"\n",
    "        Build Inception V3 transfer learning model\n",
    "        \"\"\"\n",
    "        base_model = InceptionV3(\n",
    "            weights='imagenet', \n",
    "            include_top=False, \n",
    "            input_shape=(self.img_height, self.img_width, 3)\n",
    "        )\n",
    "        \n",
    "        # Freeze base model layers\n",
    "        for layer in base_model.layers[-30:]:\n",
    "            layer.trainable = False\n",
    "        \n",
    "        # Add custom classification layers\n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        # x = Dense(\n",
    "        # 512, \n",
    "        # activation='relu', \n",
    "        # kernel_regularizer=l2(self.l2_regularization)\n",
    "        # )(x)\n",
    "        # x = BatchNormalization()(x)\n",
    "        # x = Dropout(self.dropout_rate)(x)\n",
    "        \n",
    "        x = Dense(\n",
    "            256, \n",
    "            activation='relu', \n",
    "            kernel_regularizer=l2(self.l2_regularization)\n",
    "        )(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(self.dropout_rate)(x)\n",
    "\n",
    "        predictions = Dense(\n",
    "            self.num_classes, \n",
    "            activation='softmax',\n",
    "        )(x)\n",
    "\n",
    "        \n",
    "        self.model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "        # self.model.summary()\n",
    "        \n",
    "        # Compile model\n",
    "        self.model.compile(\n",
    "            optimizer=Adam(learning_rate=learning_rate),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "\n",
    "        return self.model\n",
    "    \n",
    "    def train_with_k_fold(self, epochs=5, k_folds=5):\n",
    "        \"\"\"\n",
    "        Train model using K-Fold Cross Validation\n",
    "        \"\"\"\n",
    "        train_generator, validation_generator = self._create_data_generators()\n",
    "        \n",
    "        # K-Fold Cross Validation\n",
    "        kf = KFold(n_splits=k_folds, shuffle=True)\n",
    "        \n",
    "        # Callbacks\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_accuracy', \n",
    "            patience=10, \n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        checkpoint = ModelCheckpoint(\n",
    "            'best_face_recognition_model.keras',\n",
    "            monitor='val_accuracy', \n",
    "            save_best_only=True\n",
    "        )\n",
    "        \n",
    "        fold_histories = []\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(train_generator.classes), 1):\n",
    "            print(f\"Training Fold {fold}\")\n",
    "            \n",
    "            history = self.model.fit(\n",
    "                train_generator,\n",
    "                validation_data=validation_generator,\n",
    "                epochs=epochs,\n",
    "                callbacks=[early_stopping, checkpoint]\n",
    "            )\n",
    "            \n",
    "            fold_histories.append(history.history)\n",
    "        \n",
    "        # Load best model\n",
    "        self.best_model = tf.keras.models.load_model('best_face_recognition_model.keras')\n",
    "        \n",
    "        return fold_histories\n",
    "    \n",
    "    def evaluate_model(self, validation_generator):\n",
    "        \"\"\"\n",
    "        Evaluate model performance and generate reports\n",
    "        \"\"\"\n",
    "        # Predictions\n",
    "        predictions = self.best_model.predict(validation_generator)\n",
    "        predicted_classes = np.argmax(predictions, axis=1)\n",
    "        true_classes = validation_generator.classes\n",
    "        \n",
    "        # Classification Report\n",
    "        class_report = classification_report(\n",
    "            true_classes, \n",
    "            predicted_classes, \n",
    "            target_names=validation_generator.class_indices.keys()\n",
    "        )\n",
    "        print(\"Classification Report:\\n\", class_report)\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(true_classes, predicted_classes)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('confusionMatrix.png')\n",
    "        plt.close()\n",
    "        \n",
    "    def plot_training_history(self, histories):\n",
    "        \"\"\"\n",
    "        Plot training accuracy and loss\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        # Accuracy Plot\n",
    "        plt.subplot(1, 2, 1)\n",
    "        for history in histories:\n",
    "            plt.plot(history['accuracy'], label='Training Accuracy')\n",
    "            plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "        plt.title('Model Accuracy')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Loss Plot\n",
    "        plt.subplot(1, 2, 2)\n",
    "        for history in histories:\n",
    "            plt.plot(history['loss'], label='Training Loss')\n",
    "            plt.plot(history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Model Loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('training_history.png')\n",
    "        plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage\n",
    "def main():\n",
    "    # Configuration\n",
    "    dataset_path = \"Celebrity Faces Dataset/\"\n",
    "    \n",
    "    # Initialize and build model\n",
    "    face_recognition = FaceRecognitionModel(dataset_path)\n",
    "    model = face_recognition.build_model()\n",
    "    \n",
    "    # Train with K-Fold Cross Validation\n",
    "    histories = face_recognition.train_with_k_fold()\n",
    "    \n",
    "    # Plot training history\n",
    "    face_recognition.plot_training_history(histories)\n",
    "    \n",
    "    # Evaluate model\n",
    "    train_generator, validation_generator = face_recognition._create_data_generators()\n",
    "    face_recognition.evaluate_model(validation_generator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 886 images belonging to 10 classes.\n",
      "Found 221 images belonging to 10 classes.\n",
      "Training Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\miniconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 5s/step - accuracy: 0.2156 - loss: 2.9969 - val_accuracy: 0.3982 - val_loss: 1.9951\n",
      "Epoch 2/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 5s/step - accuracy: 0.5677 - loss: 1.3546 - val_accuracy: 0.5928 - val_loss: 1.5034\n",
      "Epoch 3/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 5s/step - accuracy: 0.6681 - loss: 0.9704 - val_accuracy: 0.7240 - val_loss: 1.0946\n",
      "Epoch 4/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 5s/step - accuracy: 0.7919 - loss: 0.6574 - val_accuracy: 0.8281 - val_loss: 0.7481\n",
      "Epoch 5/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 5s/step - accuracy: 0.8667 - loss: 0.4761 - val_accuracy: 0.8778 - val_loss: 0.5685\n",
      "Training Fold 2\n",
      "Epoch 1/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 5s/step - accuracy: 0.9086 - loss: 0.3466 - val_accuracy: 0.9050 - val_loss: 0.4817\n",
      "Epoch 2/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 5s/step - accuracy: 0.9275 - loss: 0.2799 - val_accuracy: 0.9186 - val_loss: 0.3586\n",
      "Epoch 3/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 5s/step - accuracy: 0.9284 - loss: 0.2557 - val_accuracy: 0.9457 - val_loss: 0.2552\n",
      "Epoch 4/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 5s/step - accuracy: 0.9608 - loss: 0.2087 - val_accuracy: 0.9276 - val_loss: 0.3126\n",
      "Epoch 5/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 5s/step - accuracy: 0.9724 - loss: 0.1431 - val_accuracy: 0.9457 - val_loss: 0.2898\n",
      "Training Fold 3\n",
      "Epoch 1/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 5s/step - accuracy: 0.9665 - loss: 0.1607 - val_accuracy: 0.9367 - val_loss: 0.2713\n",
      "Epoch 2/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 5s/step - accuracy: 0.9787 - loss: 0.1455 - val_accuracy: 0.9457 - val_loss: 0.2787\n",
      "Epoch 3/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 5s/step - accuracy: 0.9722 - loss: 0.1437 - val_accuracy: 0.9548 - val_loss: 0.2108\n",
      "Epoch 4/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 5s/step - accuracy: 0.9728 - loss: 0.1466 - val_accuracy: 0.9502 - val_loss: 0.2516\n",
      "Epoch 5/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 5s/step - accuracy: 0.9840 - loss: 0.1087 - val_accuracy: 0.9502 - val_loss: 0.2493\n",
      "Training Fold 4\n",
      "Epoch 1/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 5s/step - accuracy: 0.9918 - loss: 0.1158 - val_accuracy: 0.9502 - val_loss: 0.2894\n",
      "Epoch 2/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 5s/step - accuracy: 0.9829 - loss: 0.1170 - val_accuracy: 0.9638 - val_loss: 0.1824\n",
      "Epoch 3/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 5s/step - accuracy: 0.9830 - loss: 0.1092 - val_accuracy: 0.9321 - val_loss: 0.2615\n",
      "Epoch 4/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 5s/step - accuracy: 0.9885 - loss: 0.0884 - val_accuracy: 0.9412 - val_loss: 0.2237\n",
      "Epoch 5/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 5s/step - accuracy: 0.9771 - loss: 0.1050 - val_accuracy: 0.9593 - val_loss: 0.2338\n",
      "Training Fold 5\n",
      "Epoch 1/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 5s/step - accuracy: 0.9912 - loss: 0.0980 - val_accuracy: 0.9593 - val_loss: 0.1921\n",
      "Epoch 2/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 5s/step - accuracy: 0.9913 - loss: 0.0846 - val_accuracy: 0.9774 - val_loss: 0.1337\n",
      "Epoch 3/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 5s/step - accuracy: 0.9913 - loss: 0.0811 - val_accuracy: 0.9367 - val_loss: 0.2075\n",
      "Epoch 4/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 5s/step - accuracy: 0.9916 - loss: 0.0819 - val_accuracy: 0.9548 - val_loss: 0.2346\n",
      "Epoch 5/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 5s/step - accuracy: 0.9939 - loss: 0.0869 - val_accuracy: 0.9548 - val_loss: 0.1428\n",
      "Found 886 images belonging to 10 classes.\n",
      "Found 221 images belonging to 10 classes.\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      " Jennifer Lawrence       0.00      0.00      0.00        20\n",
      "       Johnny Depp       0.05      0.05      0.05        20\n",
      " Leonardo DiCaprio       0.05      0.05      0.05        20\n",
      "         Megan Fox       0.20      0.20      0.20        20\n",
      "    Michael Wijaya       0.24      0.24      0.24        21\n",
      "  Robert Downey Jr       0.25      0.25      0.25        20\n",
      "Scarlett Johansson       0.22      0.23      0.22        40\n",
      "        Tom Cruise       0.00      0.00      0.00        20\n",
      "         Tom Hanks       0.15      0.15      0.15        20\n",
      "        Will Smith       0.15      0.15      0.15        20\n",
      "\n",
      "          accuracy                           0.14       221\n",
      "         macro avg       0.13      0.13      0.13       221\n",
      "      weighted avg       0.14      0.14      0.14       221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
